# author: s-Kline
# read and preprocess data from emo cue dotprobe logfiles
# to do: compute indices and other variables of interest per subject and feed into pandas dataframe

import os
import pandas as pd
import numpy as np

def read_txtfile(txtfile, dir):
    """
    get data out of logfile and into data structure
    :param txtfile: logfile generated from emo_cue_dotprobe
    :return: subject-specific array with raw data
    """
    data = [['subject', 'iaps_cat', 'affect_rating', 'dot_probe_condition', 'reacttime', 'response', 'post_affect_order']]
    lfile = open(dir + txtfile, 'r')
    content = [l.split('\t') for l in lfile.readlines()]
    sub = txtfile[:3]
    header = content[0]
    for trial in content:
        if trial[0].isdigit():  # skip header
            if 'affect' in trial[1]:  # affect trial
                order = 0
                iaps = trial[2][:3]
                rating = trial[6]
            else:  # dot probe trial
                order += 1
                button_press = trial[6]
                dotpos = trial[7]
                replaced = trial[8]
                pics = [trial[1][0], trial[2][0]]
                pics.sort()
                cond = replaced + '_' + '_'.join(pics)
                rt = trial[5]
                if button_press == dotpos:
                    response = 'correct'
                else: response = 'incorrect'
                #response = trial[9].rstrip('\n')
                data.append([sub, iaps, rating, cond, rt, response, str(order)])
    return data

def aggregate_data(readout_files, readout_dir):
    """ takes raw reaction time data generated by read_txtfile()
        aggregates it into pandas dataframe where indices are computed
        in: rawdata-file, directory for saving dataframe
        out:
    """
    all_subjects = []
    for readout_file in readout_files:
        current_file = readout_dir + readout_file
        # create subject dataframe
        sub_df = pd.read_csv(current_file,
                             sep='\t',
                             skiprows=(0),
                             header=(0),
                             na_values='no reacttime')

        # data preprocessing
        responses = sub_df['response'].value_counts()     # count correct and incorrect responses
        reactmissings = sub_df['reacttime'].isna().sum()  # count missing reacttimes (reactions to slow)
        #print(reactmissings)

        low_thr = 0.1   # low threshold is 100 ms
        high_thr = 1.5*(sub_df['reacttime'].std()) + sub_df['reacttime'].mean()  # high threshold is 1.5*SD + mean
        rt_outliers = [i for i in sub_df['reacttime'] if i < low_thr or i > high_thr]  # check reacttimes for very small or very large values
        number_of_outliers = len(rt_outliers)
        #print(sub_df['reacttime'])
        sub_df['reacttime'] = sub_df['reacttime'].replace(to_replace=rt_outliers, value=np.nan)


        # combine iaps and condition into one variable
        sub_df['comb_cond'] = sub_df['iaps_cat'].str.cat(sub_df['dot_probe_condition'], sep='IAPS_')

        # create one row of mean affect ratings per iaps category
        ratings_df = sub_df.groupby(['iaps_cat']).mean()

        ratings_df = ratings_df.drop(columns=['reacttime', 'post_affect_order'])
        ratings_df['iaps_cat'] = ratings_df.index
        ratings_df = ratings_df.pivot(index='subject',
                                      columns='iaps_cat',
                                      values='affect_rating')

        # create one row of mean reacttimes per combined condition
        cond_df = sub_df.groupby(['comb_cond']).mean()
        cond_df['comb_cond'] = cond_df.index
        cond_df = cond_df.drop(columns = ['affect_rating', 'post_affect_order'])
        row_df = cond_df.pivot(index='subject',
                                columns='comb_cond',
                                values='reacttime')
        row_df['correct_responses'] = responses['correct']
        row_df['slow_reactions'] = reactmissings
        row_df['reaction_outliers'] = number_of_outliers
        # combine mean ratings and mean reacttimes into one row
        subject_row = pd.concat([row_df, ratings_df], axis=1)
        all_subjects.append(subject_row)
    agg_df = pd.concat(all_subjects)
    return agg_df


logdir = 'logfiles\\'
outdir = 'readout\\'
logfiles = os.listdir(logdir)

for subject in logfiles:
    # read data
    subject_log = subject
    lines = read_txtfile(subject_log, logdir)

    # save subject-specific outfiles
    outfile = subject_log[:-7] + 'rawdata.txt'
    of = open(outdir + outfile, 'w')
    for line in lines:
        of.write('\t'.join(line) + '\n')

outfiles = os.listdir(outdir)
all_subject_data = aggregate_data(outfiles, outdir)
print(all_subject_data.values)
all_subject_data.to_csv('emo_cue_dotprobe_agg_data.csv', sep='\t')
np.savetxt('agg_data.txt', all_subject_data.values,
           #fmt='%d',
           delimiter="\t",
           header='\t'.join(list(all_subject_data.columns.values)))


